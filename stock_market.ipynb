{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cudf\npd.set_option('display.max_columns', 150)\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\nimport gc\nfrom tqdm.notebook import tqdm\n\nimport warnings\nwarnings.filterwarnings(\"ignore\") # 忽略警告訊息","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import janestreet\nenv = janestreet.make_env() # initialize the environment\niter_test = env.iter_test() # an iterator which loops over the test set","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def objective(trial):    #SET optuna \n#    import optuna\n#    train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.25)\n#    dtrain = xgb.DMatrix(train_x, label=train_y)\n#    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n#   objective_list_reg = ['reg:linear', 'reg:gamma', 'reg:tweedie']\n#    metric_list = ['rmse']\n#    params ={'boosting':trial.suggest_categorical('boosting', 'gbtree'),\n#            'tree_method':trial.suggest_categorical('tree_method', 'gpu_hist'),\n#            'max_depth':trial.suggest_int('max_depth', 2, 25),\n#            'reg_alpha':trial.suggest_int('reg_alpha', 0, 5),\n#            'reg_lambda':trial.suggest_int('reg_lambda', 0, 5),\n#            'min_child_weight':trial.suggest_int('min_child_weight', 0, 5),\n#            'gamma':trial.suggest_int('gamma', 0, 5),\n#            'learning_rate':trial.suggest_loguniform('learning_rate',0.005,0.5),\n#            'eval_metric':trial.suggest_categorical('eval_metric', metric_list),\n#            'objective':trial.suggest_categorical('objective', objective_list_reg),\n#            'colsample_bytree':trial.suggest_discrete_uniform('colsample_bytree', 0.1, 1, 0.01),\n#            'colsample_bynode':trial.suggest_discrete_uniform('colsample_bynode', 0.1, 1, 0.01),\n#            'colsample_bylevel':trial.suggest_discrete_uniform('colsample_bylevel', 0.1, 1, 0.01),\n#            'subsample':trial.suggest_discrete_uniform('subsample', 0.5, 1, 0.05),\n#            'nthread' : -1  \n#     }\n#\n#    bst = xgb.train(param, dtrain)\n#    preds = bst.predict(dvalid)\n#    pred_labels = np.rint(preds)\n#    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n#    return accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def XGB(train_x, train_y):\n    import xgboost as xgb\n    model = xgb.XGBClassifier(\n    n_estimators=500,\n    max_depth=11,\n    min_child_weight=9.15,\n    gamma=0.59,\n    learning_rate=0.05,\n    subsample=0.9,\n    colsample_bytree=0.7,\n    alpha=10.4,\n    nthread=5,\n    missing=-999,\n    random_state=2020,\n    tree_method='gpu_hist')  # THE MAGICAL PARAMETER)\n    model.fit(train_x, train_y)     # 訓練模型\n    print(\"XGBoost version:\", xgb.__version__) # just run once\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Fillnan(X):\n    # fillna\n    col = {'feature_7': np.product(X['feature_7'].mode()),'feature_8': np.product(X['feature_8'].mode()),'feature_72': np.product(X['feature_72'].mode()),'feature_78': np.product(X['feature_78'].mode())}\n    #col2 = {'feature_11': np.product(X['feature_11'].mode()),'feature_12': np.product(X['feature_12'].mode()),'feature_13': np.product(X['feature_13'].mode()),'feature_14': np.product(X['feature_14'].mode()),'feature_74': np.product(X['feature_74'].mode()),'feature_75': np.product(X['feature_75'].mode()),'feature_80': np.product(X['feature_80'].mode()),'feature_81': np.product(X['feature_81'].mode())}\n    col2 = {'feature_74': np.product(X['feature_74'].mode()),'feature_75': np.product(X['feature_75'].mode()),'feature_80': np.product(X['feature_80'].mode()),'feature_81': np.product(X['feature_81'].mode())}\n    X.fillna(value=col,inplace=True)\n    X.fillna(value=col2,inplace=True)\n    del col,col2\n    return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Average(X):\n    # feature avg\n    num = 0\n    i = 0\n    for feature in X:\n        #if (i != 7) and (i != 8) and (i != 72) and (i != 78):\n        if (i != 7) and (i != 8) and (i != 72) and (i != 78) and (i != 74) and (i != 75) and (i != 80) and (i != 81):\n        #if (i != 7) and (i != 8) and (i != 72) and (i != 78) and (i != 11) and (i != 12) and (i != 13) and (i != 14) and (i != 74) and (i != 75) and (i != 80) and (i != 81):\n            indx1 = X[feature] > 0\n            indx2 = indx1 == False\n            train[feature][indx1] =  1\n            train[feature][indx2] = -1\n            #train[feature] = X[feature].apply(lambda x:1 if x > 0 else -1) # 以X為條件將train[feature]的Data分兩類\n            check = train[[feature, 'resp']].groupby([feature], as_index=False).mean().sort_values(by='resp', ascending=False) #1,-1分群\n            if check['resp'][0] > check['resp'][1]:\n                num += check['resp'][0] - check['resp'][1] # 求出所有feature差和\n            else:\n                num += check['resp'][1] - check['resp'][0]\n            del check\n        i+=1\n    #avg = num/126\n    avg = num/122\n    #avg = num/118  \n    return avg\n    #0.0005615499604115825\n    #\n    #0.0005621298415324371","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Feature(avg,X):\n    val = 0\n    i = 0\n    needft = []\n    for feature in X:\n        #if (i != 7) and (i != 8) and (i != 72) and (i != 78):\n        if (i != 7) and (i != 8) and (i != 72) and (i != 78) and (i != 74) and (i != 75) and (i != 80) and (i != 81):\n        #if (i != 7) and (i != 8) and (i != 72) and (i != 78) and (i != 11) and (i != 12) and (i != 13) and (i != 14) and (i != 74) and (i != 75) and (i != 80) and (i != 81):\n            indx1 = X[feature] > 0\n            indx2 = indx1 == False\n            train[feature][indx1] =  1\n            train[feature][indx2] = -1\n            #train[feature] = X[feature].apply(lambda x:1 if x > 0 else -1) # 以X為條件將train[feature]的Data分兩類\n            check = train[[feature, 'resp']].groupby([feature], as_index=False).mean().sort_values(by='resp', ascending=False) # 求兩類平均resp\n            if check['resp'][0] > check['resp'][1]: # 大-小\n                val = check['resp'][0] - check['resp'][1]\n            else:\n                val = check['resp'][1] - check['resp'][0]\n            if (val - avg) > 0:    # 差 - 平均差\n                #X[feature] = X[feature].apply(lambda x:1 if x > 0 else -1)\n                needft.append(feature)\n            del check,val\n        i+=1\n    del i\n    for feature in needft: # 只做val - avg > 0的data\n        indx1 = X[feature] > 0\n        indx2 = indx1 == False\n        X[feature][indx1] =  1\n        X[feature][indx2] = -1\n    del indx1,indx2,needft\n    return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# load Data\ntrain_cudf  = cudf.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\ntrain = train_cudf.to_pandas()\ndel train_cudf\nfeatures = pd.read_csv('../input/jane-street-market-prediction/features.csv')\nexample_test = pd.read_csv('../input/jane-street-market-prediction/example_test.csv')\nsample_prediction_df = pd.read_csv('../input/jane-street-market-prediction/example_sample_submission.csv')\nprint (\"Data is loaded!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# draw line chart\nfig, ax = plt.subplots(figsize=(15, 5))\nbalance= pd.Series(train['resp']).cumsum()\nresp_1= pd.Series(train['resp_1']).cumsum()\nresp_2= pd.Series(train['resp_2']).cumsum()\nresp_3= pd.Series(train['resp_3']).cumsum()\nresp_4= pd.Series(train['resp_4']).cumsum()\nax.set_xlabel (\"Trade\", fontsize=18)\nax.set_title (\"Cumulative resp and time horizons 1, 2, 3, 4\", fontsize=18)\nbalance.plot(lw=3)\nresp_1.plot(lw=3)\nresp_2.plot(lw=3)\nresp_3.plot(lw=3)\nresp_4.plot(lw=3)\nplt.legend(loc=\"upper left\");\ndel resp_1\ndel resp_2\ndel resp_3\ndel resp_4\ngc.collect();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12,5))\nax = sns.distplot(train['feature_117'],\n                 bins=3000,\n                 kde_kws={\"clip\":(-5,5)},\n                 hist_kws={\"range\":(-5,5)},\n                 color='darkcyan',\n                 kde=False);\nvalues = np.array([rec.get_height() for rec in ax.patches])\nnorm = plt.Normalize(values.min(), values.max())\ncolors = plt.cm.jet(norm(values))\nfor rec, col in zip(ax.patches, colors):\n    rec.set_color(col)\nplt.xlabel(\"Histogram of the resp values\", size=14)\nplt.show();\ndel values\ngc.collect();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check\ncheck = train.copy()\ncheck = check.fillna(value={'feature_2': np.product(train['feature_2'].mode())})\ncheck['feature_2'] = check['feature_2'].apply(lambda x:1 if x<-3 else -1)\ncheck = check[['feature_2', 'resp']].groupby(['feature_2'], as_index=False).mean().sort_values(by='resp', ascending=False) #1,-1分群\nck = train['feature_84'].mean()\nprint(check)\n\ntag = features\nnew_tag = []\ndraw = []\nfor tg in tag:\n    if (tag[tg][108] == True) and (tag[tg][114] == True) and (tag[tg][121] == True):\n        new_tag.append(tg)\n        print(tg)\nfor tg in new_tag:\n    view = tag[tg] == True\n    print('tag is ' + tg)\n    print(tag['feature'][view])\n    draw.append(tag['feature'][view])\n\ndel ck,check,tag,new_tag","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# draw missing value \nmiss = train.isnull().sum()\npx.bar(miss, color=miss.values, title=\"Total number of missing values for each column\").show()\ndel miss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# missing value%\nmissing_values_count = train.isnull().sum()\nprint (missing_values_count)\ntotal_cells = np.product(train.shape)\ntotal_missing = missing_values_count.sum()\nm = missing_values_count['feature_9'].sum()\nc = np.product(train['feature_9'].shape)\nprint(\"features % = \",m/c*100)\nprint (\"% of missing data = \",(total_missing/total_cells) * 100)\ndel m,c","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainX,labelY\ntarget = train['weight'] != 0 # weight==0無參考價值\ntrain = train[target]\ntrain['action'] = (train['resp'].values > 0).astype('int') # >0才進場投資\n\nX = train.loc[:, train.columns.str.contains('feature')]  # 取出有features的\n#X = X.drop(['feature_17','feature_18','feature_27','feature_28','feature_84','feature_90','feature_96','feature_102','feature_108','feature_114'],axis=1)\ny = train['action']\n\ndel target","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX = Fillnan(X)\nX.fillna(X.mean(),inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\navg = Average(X)\nprint(avg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nX = Feature(avg,X) # 1,-1\ndel train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optuna\n#study = optuna.create_study(direction=\"maximize\")\n#study.optimize(objective, n_trials=100)\n\n#print(\"Number of finished trials: \", len(study.trials))\n#print(\"Best trial:\")\n#trial = study.best_trial","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel = XGB(X,y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (test_df, prediction_df) in tqdm(iter_test):\n    if test_df['weight'].item() > 0: \n        X_test = test_df.loc[:, test_df.columns.str.contains('feature')]\n        X_test = Fillnan(X_test)\n        #X_test.fillna(-999,inplace=True)\n        prediction_df.action = model.predict(X_test)\n    else:\n        prediction_df.action = 0\n    env.predict(prediction_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}